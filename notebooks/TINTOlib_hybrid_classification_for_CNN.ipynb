{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EybOZ6hSjpCF"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=5>TINTOlib: Converting Tidy Data into Image for Classification with 2-Dimensional Convolutional Neural Networks</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#113D68\" size=6>How to read TINTO images</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#113D68\" size=3>Raúl García-Castro</font><br>\n",
    "<font color=\"#113D68\" size=3>Luis Orozco-Barbosa</font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l5nFzsdjpCW"
   },
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Index</font></h2>\n",
    "\n",
    "* [0. Context](#section0)\n",
    "* [1. Description](#section1)\n",
    "    * [1.1. Main Features](#section12)\n",
    "    * [1.2. Citation](#section12)\n",
    "* [2. Libraries](#section2)\n",
    "* [3. Data processing](#section3)\n",
    "    * [3.1. Read images](#section31)\n",
    "    * [3.2. Data Curation](#section32)\n",
    "* [4. Pre-modelling phase](#section4)\n",
    "    * [4.1. Resize images](#section41)\n",
    "    * [4.2. Iteradores](#section42)\n",
    "* [5. Modelling with CNN](#section5)\n",
    "    * [5.1. CNN](#section51)\n",
    "    * [5.2. Compile and fit](#section52)\n",
    "    * [5.3. Results](#section53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxTpMExHjpCa"
   },
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Context</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlVYt3MRrl_V"
   },
   "source": [
    "This is a tutorial on how to read the images created by TINTO and pass them to a very simple pretrained Convolutional Neural Network (CNN). The images must already be created by the TINTO software. See the documentation in GITHUB for how to create the images from tabular data.\n",
    "\n",
    "Remember that when using CNN you can set the training to be done with GPUs to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaA-_OjsjpCe"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "See the paper from [Information Fusion Journal](https://doi.org/10.1016/j.inffus.2022.10.011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28TFDkl5jpCi"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "See the paper from [SoftwareX](https://doi.org/10.1016/j.softx.2023.101391)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTO in [GitHub](https://github.com/oeg-upm/TINTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RKBgDwzjpCl"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpU7pi6yjpCn"
   },
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 1. Description</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL9RoFkEjpCq"
   },
   "source": [
    "The growing interest in the use of algorithms-based machine learning for predictive tasks has generated a large and diverse development of algorithms. However, it is widely known that not all of these algorithms are adapted to efficient solutions in certain tidy data format datasets. For this reason, novel techniques are currently being developed to convert tidy data into images with the aim of using Convolutional Neural Networks (CNNs). TINTO offers the opportunity to convert tidy data into images through the representation of characteristic pixels by implementing two dimensional reduction algorithms: PCA and _t_-SNE. Our proposal also includes a blurring technique, which adds more ordered information to the image and can improve the classification task in CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFrF4C89jpCt"
   },
   "source": [
    "---\n",
    "<a id=\"section11\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.1. Main Features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gruE0_sjpCu"
   },
   "source": [
    "- Supports all CSV data in **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "- For now, the algorithm converts tabular data for binary and multi-class classification problems into machine learning.\n",
    "- Input data formats:\n",
    "    - **Tabular files**: The input data must be in **[CSV](https://en.wikipedia.org/wiki/Comma-separated_values)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Tidy Data**: The **target** (variable to be predicted) should be set as the last column of the dataset. Therefore, the first columns will be the features.\n",
    "    - All data must be in numerical form. TINTO does not accept data in string or any other non-numeric format.\n",
    "- Two dimensionality reduction algorithms are used in image creation, **[PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)** and **[*t*-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)** from the Scikit-learn Python library.\n",
    "- The synthetic images to be created will be in black and white, i.e. in 1 channel.\n",
    "- The synthetic image **dimensions** can be set as a parameter when creating them.\n",
    "- The synthetic images can be created using **characteristic pixels** or **blurring** painting technique (expressing an overlap of pixels as the **maximum** or **average**).\n",
    "- Runs on **Linux**, **Windows** and **macOS** systems.\n",
    "- Compatible with **[Python](https://www.python.org/)** 3.7 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3EzYcjJjpC6"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwYF5A2njpC8"
   },
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 2. Libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AdHKnWYsEq_"
   },
   "source": [
    "The first thing we need to do is to declare the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "PeeBbGxlpjFp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers  import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwS-cKUxjpDQ"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDL4LARWjpDT"
   },
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 3. Data processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXcRw78ljpDU"
   },
   "source": [
    "The first thing to do is to read all the images created by TINTO. TINTO creates a folder which contains subfolders corresponding to each target that has the problem. Each image corresponds to a sample of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section31\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.1. Create images with TINTOlib</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"supervised\"\n",
    "image_model = TINTO(problem= problem_type,pixels=224)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "dataset_path = \"C:\\\\Users\\\\Borja\\\\PycharmProjects\\\\TINTORERA\\\\Datasets\\\\cancer.csv \"\n",
    "images_folder = \"C:\\\\Users\\\\Borja\\\\PycharmProjects\\\\TINTORERA\\\\tintoimagesregression\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.643144  0.272574  0.615783  0.501591  0.289880  0.181768  0.203608   \n",
       "1  0.601496  0.390260  0.595743  0.449417  0.514309  0.431017  0.462512   \n",
       "\n",
       "          7         8         9  ...        21        22        23        24  \\\n",
       "0  0.348757  0.379798  0.141323  ...  0.303571  0.539818  0.435214  0.347553   \n",
       "1  0.635686  0.509596  0.211247  ...  0.360075  0.508442  0.374508  0.483590   \n",
       "\n",
       "         25        26        27        28        29   45  \n",
       "0  0.154563  0.192971  0.639175  0.233590  0.222878  1.0  \n",
       "1  0.385375  0.359744  0.835052  0.403706  0.213433  1.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.643144  0.272574  0.615783  0.501591  0.289880  0.181768  0.203608   \n",
       "1  0.601496  0.390260  0.595743  0.449417  0.514309  0.431017  0.462512   \n",
       "\n",
       "          7         8         9  ...        21        22        23        24  \\\n",
       "0  0.348757  0.379798  0.141323  ...  0.303571  0.539818  0.435214  0.347553   \n",
       "1  0.635686  0.509596  0.211247  ...  0.360075  0.508442  0.374508  0.483590   \n",
       "\n",
       "         25        26        27        28        29   45  \n",
       "0  0.154563  0.192971  0.639175  0.233590  0.222878  1.0  \n",
       "1  0.385375  0.359744  0.835052  0.403706  0.213433  1.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all the attributes to normalize\n",
    "columns_to_normalize = df.columns[:-1]\n",
    "\n",
    "# Normalize between 0 and 1\n",
    "df_normalized = (df[columns_to_normalize] - df[columns_to_normalize].min()) / (df[columns_to_normalize].max() - df[columns_to_normalize].min())\n",
    "\n",
    "# Combine the attributes and the label\n",
    "df_normalized = pd.concat([df_normalized, df[df.columns[-1]]], axis=1)\n",
    "\n",
    "num_attributes = len(df.columns.tolist()) -1\n",
    "num_classes = df_normalized.iloc[:, -1].nunique()\n",
    "\n",
    "df_normalized.head(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tintoimagesregression\\supervised.csv\n"
     ]
    }
   ],
   "source": [
    "#Generate thet images\n",
    "image_model.generateImages(df_normalized, images_folder)\n",
    "\n",
    "img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "\n",
    "print(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klS9PZsUjpDV"
   },
   "source": [
    "<a id=\"section32\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.2. Read images</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.258839</td>\n",
       "      <td>0.202570</td>\n",
       "      <td>0.267984</td>\n",
       "      <td>0.141506</td>\n",
       "      <td>0.678613</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.369728</td>\n",
       "      <td>0.402038</td>\n",
       "      <td>0.518687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312633</td>\n",
       "      <td>0.263908</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.712739</td>\n",
       "      <td>0.482784</td>\n",
       "      <td>0.427716</td>\n",
       "      <td>0.598282</td>\n",
       "      <td>0.477035</td>\n",
       "      <td>0.454939</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                images         0         1  \\\n",
       "0    C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.643144  0.272574   \n",
       "1    C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.601496  0.390260   \n",
       "2    C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.210090  0.360839   \n",
       "3    C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.629893  0.156578   \n",
       "4    C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.258839  0.202570   \n",
       "..                                                 ...       ...       ...   \n",
       "563  C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.690000  0.428813   \n",
       "564  C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.622320  0.626987   \n",
       "565  C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.455251  0.621238   \n",
       "566  C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.644564  0.663510   \n",
       "567  C:\\Users\\Borja\\PycharmProjects\\TINTORERA\\tinto...  0.036869  0.501522   \n",
       "\n",
       "            2         3         4         5         6         7         8  \\\n",
       "0    0.615783  0.501591  0.289880  0.181768  0.203608  0.348757  0.379798   \n",
       "1    0.595743  0.449417  0.514309  0.431017  0.462512  0.635686  0.509596   \n",
       "2    0.233501  0.102906  0.811321  0.811361  0.565604  0.522863  0.776263   \n",
       "3    0.630986  0.489290  0.430351  0.347893  0.463918  0.518390  0.378283   \n",
       "4    0.267984  0.141506  0.678613  0.461996  0.369728  0.402038  0.518687   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "563  0.678668  0.566490  0.526948  0.296055  0.571462  0.690358  0.336364   \n",
       "564  0.604036  0.474019  0.407782  0.257714  0.337395  0.486630  0.349495   \n",
       "565  0.445788  0.303118  0.288165  0.254340  0.216753  0.263519  0.267677   \n",
       "566  0.665538  0.475716  0.588336  0.790197  0.823336  0.755467  0.675253   \n",
       "567  0.028540  0.015907  0.000000  0.074351  0.000000  0.000000  0.266162   \n",
       "\n",
       "     ...        21        22        23        24        25        26  \\\n",
       "0    ...  0.303571  0.539818  0.435214  0.347553  0.154563  0.192971   \n",
       "1    ...  0.360075  0.508442  0.374508  0.483590  0.385375  0.359744   \n",
       "2    ...  0.385928  0.241347  0.094008  0.915472  0.814012  0.548642   \n",
       "3    ...  0.123934  0.506948  0.341575  0.437364  0.172415  0.319489   \n",
       "4    ...  0.312633  0.263908  0.136748  0.712739  0.482784  0.427716   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "563  ...  0.383262  0.576174  0.452664  0.461137  0.178527  0.328035   \n",
       "564  ...  0.699094  0.520892  0.379915  0.300007  0.159997  0.256789   \n",
       "565  ...  0.589019  0.379949  0.230731  0.282177  0.273705  0.271805   \n",
       "566  ...  0.730277  0.668310  0.402035  0.619626  0.815758  0.749760   \n",
       "567  ...  0.489072  0.043578  0.020497  0.124084  0.036043  0.000000   \n",
       "\n",
       "           27        28        29   45  \n",
       "0    0.639175  0.233590  0.222878  1.0  \n",
       "1    0.835052  0.403706  0.213433  1.0  \n",
       "2    0.884880  1.000000  0.773711  1.0  \n",
       "3    0.558419  0.157500  0.142595  1.0  \n",
       "4    0.598282  0.477035  0.454939  1.0  \n",
       "..        ...       ...       ...  ...  \n",
       "563  0.761512  0.097575  0.105667  1.0  \n",
       "564  0.559450  0.198502  0.074315  1.0  \n",
       "565  0.487285  0.128721  0.151909  1.0  \n",
       "566  0.910653  0.497142  0.452315  1.0  \n",
       "567  0.000000  0.257441  0.100682 -1.0  \n",
       "\n",
       "[568 rows x 32 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = pd.read_csv(img_paths)\n",
    "imgs[\"images\"]= images_folder + \"\\\\\" + imgs[\"images\"]\n",
    "\n",
    "#Delete duplicated class\n",
    "imgs = imgs.drop(\"class\",axis=1)\n",
    "\n",
    "combined_dataset = pd.concat([imgs,df_normalized],axis=1)\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_haEKIo7jpD1"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF1lJWbojpD3"
   },
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 4. Pre-modelling phase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2JfptcrjpD5"
   },
   "source": [
    "Create the custom Dataset reader and hybrid model using LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Tabular and Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.tabular = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tabular)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tabular = self.tabular.iloc[idx, 0:]\n",
    "\n",
    "        y = tabular[ -1]\n",
    "  \n",
    "        image = Image.open(tabular['images'])\n",
    "        #print(image.width, image.height)\n",
    "        image = np.array(image)\n",
    "        image = image[..., :3]\n",
    "        \n",
    "\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        columns = self.tabular.columns[1:-1].tolist()\n",
    "        tabular = tabular[columns]\n",
    "        tabular = tabular.tolist()\n",
    "        tabular = torch.FloatTensor(tabular)\n",
    "\n",
    "        return image, tabular, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def conv_block(input_size, output_size):\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, (3, 3)), nn.ReLU(), nn.BatchNorm2d(output_size), nn.MaxPool2d((2, 2)),\n",
    "    )\n",
    "\n",
    "    return block\n",
    "\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, lr: float = 1e-3, num_workers: int = 16, batch_size: int = 8,\n",
    "        \n",
    "        \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.conv1 = conv_block(3, 16)\n",
    "        self.conv2 = conv_block(16, 32)\n",
    "        self.conv3 = conv_block(32, 64)\n",
    "\n",
    "        self.ln1 = nn.Linear(64 * 26 * 26, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm = nn.BatchNorm1d(16)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.ln2 = nn.Linear(16, num_attributes)\n",
    "        #13 attributes\n",
    "\n",
    "        self.ln4 = nn.Linear(30, 10)\n",
    "        self.ln5 = nn.Linear(10, 10)\n",
    "        self.ln6 = nn.Linear(10, num_attributes)\n",
    "        \n",
    "        self.ln7 = nn.Linear(num_attributes*2, num_classes)\n",
    "        \n",
    "        self.train_loss_values = []\n",
    "        \n",
    " \n",
    "    \n",
    "    def forward(self, img, tab):\n",
    "        img = self.conv1(img)\n",
    "        img = self.conv2(img)\n",
    "        img = self.conv3(img)\n",
    "        img = img.reshape(img.shape[0], -1)\n",
    "        img = self.ln1(img)\n",
    "        img = self.relu(img)\n",
    "        img = self.batchnorm(img)\n",
    "        img = self.dropout(img)\n",
    "        img = self.ln2(img)\n",
    "        img = self.relu(img)\n",
    "\n",
    "        tab = self.ln4(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln5(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln6(tab)\n",
    "        tab = self.relu(tab)\n",
    "\n",
    "        x = torch.cat((img, tab), dim=1)\n",
    "\n",
    "        x = F.softmax(x) \n",
    "\n",
    "        return self.ln7(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image, tabular, y = batch\n",
    "        #MAE\n",
    "        #criterion = torch.nn.L1Loss()\n",
    "        #MAPE\n",
    "        #criterion = MeanAbsolutePercentageError()\n",
    "        #Cross Entropy\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "      \n",
    "        y_pred = torch.flatten(self(image, tabular))\n",
    "        y_pred = y_pred.double()\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        #print(y_pred,y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        \n",
    "        # Append the loss value to the train_loss_values list\n",
    "        #self.train_loss_values.append(loss.item())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image, tabular, y = batch\n",
    "\n",
    "        #MAE\n",
    "        #criterion = torch.nn.L1Loss()\n",
    "        #MAPE\n",
    "        #criterion = MeanAbsolutePercentageError()\n",
    "        #Cross Entropy\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        print(len(image))\n",
    "        print(len(tabular))\n",
    "        print(len(y))\n",
    "\n",
    "        \n",
    "        y_pred = torch.flatten(self(image, tabular))\n",
    "        #y_pred = y_pred.double()\n",
    "        print(len(y_pred),len(y))\n",
    "        val_loss = criterion(y_pred, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "        return val_loss\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        image, tabular, y = batch\n",
    "\n",
    "        #MAE\n",
    "        #criterion = torch.nn.L1Loss()\n",
    "        #MAPE\n",
    "        #criterion = MeanAbsolutePercentageError()\n",
    "        #Cross Entropy\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        y_pred = torch.flatten(self(image, tabular))\n",
    "        y_pred = y_pred.double()\n",
    "\n",
    "        test_loss = criterion(y_pred, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        return test_loss\n",
    "\n",
    "    \n",
    "    def setup(self, stage):\n",
    "\n",
    "        image_data = ImageDataset(dataset=combined_dataset)\n",
    "\n",
    "        train_size = int(0.80 * len(image_data))\n",
    "        val_size = int((len(image_data) - train_size) / 2)\n",
    "        test_size = int((len(image_data) - train_size) / 2)\n",
    "        print(train_size,val_size,test_size)\n",
    "        self.train_set, self.val_set, self.test_set = random_split(image_data, (train_size, val_size, test_size))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=(self.lr))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoryCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_loss_history = []\n",
    "        self.val_loss_history = []\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Get the logged loss values from the trainer\n",
    "        train_loss_values = trainer.callback_metrics['train_loss']\n",
    "        # Append the loss values to the train_loss_history list\n",
    "        self.train_loss_history.append(train_loss_values)\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Get the logged loss values from the trainer\n",
    "        val_loss_values = trainer.callback_metrics['val_loss']\n",
    "        # Append the loss values to the train_loss_history list\n",
    "        self.val_loss_history.append(val_loss_values)\n",
    "        #print(len(self.val_loss_history),val_loss_values)\n",
    "        \n",
    "        \n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=5000, patience=20, verbose=False, mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 5. Training phase</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name      | Type        | Params\n",
      "-------------------------------------------\n",
      "0  | conv1     | Sequential  | 480   \n",
      "1  | conv2     | Sequential  | 4.7 K \n",
      "2  | conv3     | Sequential  | 18.6 K\n",
      "3  | ln1       | Linear      | 692 K \n",
      "4  | relu      | ReLU        | 0     \n",
      "5  | batchnorm | BatchNorm1d | 32    \n",
      "6  | dropout   | Dropout     | 0     \n",
      "7  | ln2       | Linear      | 510   \n",
      "8  | ln4       | Linear      | 310   \n",
      "9  | ln5       | Linear      | 110   \n",
      "10 | ln6       | Linear      | 330   \n",
      "11 | ln7       | Linear      | 122   \n",
      "-------------------------------------------\n",
      "717 K     Trainable params\n",
      "0         Non-trainable params\n",
      "717 K     Total params\n",
      "2.870     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454 57 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c97431d439f44c68695628347559acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Borja\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Borja\\AppData\\Local\\Temp\\ipykernel_14364\\2701969114.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "16 8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [16], target: [8])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LitClassifier()\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[HistoryCallback(),early_stop_callback])\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[0;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    555\u001b[0m     ckpt_path,\n\u001b[0;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    558\u001b[0m )\n\u001b[1;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    932\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:976\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m--> 976\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1005\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1002\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1005\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1007\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     previous_dataloader_idx \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[0;32m    374\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 375\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    379\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:288\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 288\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    291\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[174], line 106\u001b[0m, in \u001b[0;36mLitClassifier.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m#y_pred = y_pred.double()\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred),\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[1;32m--> 106\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_loss)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_loss\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch (got input: [16], target: [8])"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LitClassifier()\n",
    "trainer = pl.Trainer(max_epochs = 10, callbacks=[HistoryCallback(),early_stop_callback])\n",
    "\n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section52\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.2. Results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_loss_history = trainer.callbacks[0].train_loss_history\n",
    "val_loss_history = trainer.callbacks[0].val_loss_history\n",
    "\n",
    "train_lh = [tensor.item()*100 for tensor in train_loss_history]\n",
    "val_lh = [tensor.item()*100 for tensor in val_loss_history]\n",
    "\n",
    "s1 = pd.DataFrame({\"MAPE\": train_lh})\n",
    "s2 = pd.DataFrame({\"MAPE\": val_lh})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(x=range(len(s1[\"MAPE\"])), y=s1[\"MAPE\"], ax=ax, label='train')\n",
    "sns.lineplot(x=range(len(s2[\"MAPE\"])), y= s2[\"MAPE\"], ax=ax, label='validation')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MAPE')\n",
    "\n",
    "ax.set_ylim(0,100)\n",
    "\n",
    "#Mean baseline\n",
    "#ax.axhline(y=mean_baseline, linestyle='dotted', color='red', label = 'mean_baseline')\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig(\"training_validation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ciBS76mpjGU"
   },
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1plFq1CpEXIdc9LankaLPiOObRg0_y5l2",
     "timestamp": 1684250343977
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
