{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EybOZ6hSjpCF"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=6>TINTOlib: Converting Tidy Data into Image for 2-Dimensional Convolutional Neural Networks</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Template Classification Machine Learning problem with a CNN</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#113D68\" size=3>Raúl García-Castro</font><br>\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "More information about [Manuel Castillo-Cara](https://www.manuelcastillo.eu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "More information about [Raúl García-Castro](http://www.garcia-castro.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l5nFzsdjpCW"
   },
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Index</font></h2>\n",
    "\n",
    "* [0. Context](#section0)\n",
    "* [1. Description](#section1)\n",
    "    * [1.1. Main Features](#section11)\n",
    "    * [1.2. Citation](#section12)\n",
    "    * [1.3. Documentation and License](#section13)\n",
    "* [2. Libraries](#section2)\n",
    "    * [2.1. System setup](#section21)\n",
    "    * [2.2. Invoke the libraries](#section22)\n",
    "* [3. Data processing](#section3)\n",
    "    * [3.1. TINTOlib methods](#section31)\n",
    "    * [3.2. Read the dataset](#section32)\n",
    "    * [3.3. Generate images](#section33)\n",
    "    * [3.4. Read images](#section34)\n",
    "* [4. Pre-modelling phase](#section4)\n",
    "    * [4.1. Data curation](#section41)\n",
    "    * [4.2. Resize Images](#section42)\n",
    "    * [4.3. Iterators](#section43)\n",
    "* [5. Modelling with CNN](#section5)\n",
    "    * [5.1. CNN](#section51)\n",
    "    * [5.2. Compile and fit](#section52)\n",
    "* [6. Results](#section6)\n",
    "    * [6.1. Train/Validation representation](#section61)\n",
    "    * [6.2. Validation/Test evaluation](#section62)\n",
    "    * [6.3. Sklearn metrics evaluation](#section63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxTpMExHjpCa"
   },
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Context</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlVYt3MRrl_V"
   },
   "source": [
    "This is a tutorial on how to read the images created by TINTO and pass them to a very simple pretrained Convolutional Neural Network (CNN). The images must already be created by the TINTOlib software. See the documentation in GITHUB for how to create the images from tabular data.\n",
    "\n",
    "Remember that when using CNN you can set the training to be done with GPUs to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib code in [GitHub](https://github.com/oeg-upm/TINTOlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RKBgDwzjpCl"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpU7pi6yjpCn"
   },
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 1. Description</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL9RoFkEjpCq"
   },
   "source": [
    "The growing interest in the use of algorithms-based machine learning for predictive tasks has generated a large and diverse development of algorithms. However, it is widely known that not all of these algorithms are adapted to efficient solutions in certain tidy data format datasets. For this reason, novel techniques are currently being developed to convert tidy data into images with the aim of using Convolutional Neural Networks (CNNs). TINTOlib offers the opportunity to convert tidy data into images through several techniques: TINTO, IGTD, REFINED, SuperTML, BarGraph, DistanceMatrix and Combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFrF4C89jpCt"
   },
   "source": [
    "---\n",
    "<a id=\"section11\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.1. Main Features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gruE0_sjpCu"
   },
   "source": [
    "- Supports all CSV data in **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "- For now, the algorithm converts tabular data for binary and multi-class classification problems into machine learning.\n",
    "- Input data formats:\n",
    "    - **Tabular files**: The input data could be in **[CSV](https://en.wikipedia.org/wiki/Comma-separated_values)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Dataframe***: The input data could be in **[Pandas Dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Tidy Data**: The **target** (variable to be predicted) should be set as the last column of the dataset. Therefore, the first columns will be the features.\n",
    "    - All data must be in numerical form. TINTOlib does not accept data in string or any other non-numeric format.\n",
    "- Runs on **Linux**, **Windows** and **macOS** systems.\n",
    "- Compatible with **[Python](https://www.python.org/)** 3.7 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section12\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.2. Citation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TINTOlib** is an python library that makes **Synthetic Images** from [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) (also knows as **Tabular Data**).\n",
    "\n",
    "**Citing TINTO**: If you used TINTO in your work, please cite the **[SoftwareX](https://doi.org/10.1016/j.softx.2023.101391)**:\n",
    "\n",
    "```bib\n",
    "@article{softwarex_TINTO,\n",
    "    title = {TINTO: Converting Tidy Data into Image for Classification\n",
    "            with 2-Dimensional Convolutional Neural Networks},\n",
    "    journal = {SoftwareX},\n",
    "    author = {Manuel Castillo-Cara and Reewos Talla-Chumpitaz and\n",
    "              Raúl García-Castro and Luis Orozco-Barbosa},\n",
    "    year = {2023},\n",
    "    pages = {101391},\n",
    "    issn = {2352-7110},\n",
    "    doi = {https://doi.org/10.1016/j.softx.2023.101391}\n",
    "}\n",
    "```\n",
    "\n",
    "And use-case developed in **[INFFUS Paper](https://doi.org/10.1016/j.inffus.2022.10.011)**\n",
    "\n",
    "```bib\n",
    "@article{inffus_TINTO,\n",
    "    title = {A novel deep learning approach using blurring image\n",
    "            techniques for Bluetooth-based indoor localisation},\n",
    "    journal = {Information Fusion},\n",
    "    author = {Reewos Talla-Chumpitaz and Manuel Castillo-Cara and\n",
    "              Luis Orozco-Barbosa and Raúl García-Castro},\n",
    "    volume = {91},\n",
    "    pages = {173-186},\n",
    "    year = {2023},\n",
    "    issn = {1566-2535},\n",
    "    doi = {https://doi.org/10.1016/j.inffus.2022.10.011}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section13\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.3. Documentation and License</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TINTOlib has a wide range of documentation on both GitHub and PiPY. \n",
    "\n",
    "Moreover, TINTOlib is free and open software with Apache 2.0 license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib code in [GitHub](https://github.com/oeg-upm/TINTOlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3EzYcjJjpC6"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwYF5A2njpC8"
   },
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 2. Libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFrF4C89jpCt"
   },
   "source": [
    "---\n",
    "<a id=\"section21\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 2.1. System setup</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before installing the libraries you must have the `mpi4py` package installed on the native (Linux) system. This link shows how to install it: \n",
    "- [mpi4py in Linux](https://www.geeksforgeeks.org/how-to-install-python3-mpi4py-package-on-linux/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in Linux:\n",
    "\n",
    "```\n",
    "    sudo apt-get install python3\n",
    "    sudo apt install python3-pip\n",
    "    sudo apt install python3-mpi4py\n",
    "```\n",
    "\n",
    "If you are in Windows, Mac or, also, Linux, you can install from PyPI if you want:\n",
    "```\n",
    "    sudo pip3 install mpi4py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Note that you must **restart the kernel or the system** so that it can load the libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once you have installed `mpi4py` you can install the PyPI libraries and dependences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics pytorch_lightning TINTOlib imblearn keras_preprocessing mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Note that you must **restart the kernel** so that it can load the libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFrF4C89jpCt"
   },
   "source": [
    "---\n",
    "<a id=\"section22\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 2.2. Invoke the libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AdHKnWYsEq_"
   },
   "source": [
    "The first thing we need to do is to declare the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PeeBbGxlpjFp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/d3b8zc6j5019cyvmb_h929xm0000gn/T/ipykernel_7486/2800590509.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/manwest/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwS-cKUxjpDQ"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDL4LARWjpDT"
   },
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 3. Data processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLzynCxOpHBX"
   },
   "source": [
    "---\n",
    "<a id=\"section31\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.1. TINTOlib methods</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the declaration of the classes with the TINTOlib method we want to transform. Note that TINTOlib has several methods and we will have to choose one of them since each method generates different images.\n",
    "\n",
    "In addition, we establish the paths where the dataset is located and also the folder where the images will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"supervised\"\n",
    "image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "#image_model = TINTO(problem= problem_type,blur=True)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "dataset_path = \"cancer.csv\"\n",
    "images_folder = \"images\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all TINTOlib method in the [PyPI documentation](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLzynCxOpHBX"
   },
   "source": [
    "---\n",
    "<a id=\"section32\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.2. Read the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we proceed to read the dataset according to the path specified above and also standardize the name that the target will have, in this case, it will be called _class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.258839</td>\n",
       "      <td>0.202570</td>\n",
       "      <td>0.267984</td>\n",
       "      <td>0.141506</td>\n",
       "      <td>0.678613</td>\n",
       "      <td>0.461996</td>\n",
       "      <td>0.369728</td>\n",
       "      <td>0.402038</td>\n",
       "      <td>0.518687</td>\n",
       "      <td>0.551179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312633</td>\n",
       "      <td>0.263908</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.712739</td>\n",
       "      <td>0.482784</td>\n",
       "      <td>0.427716</td>\n",
       "      <td>0.598282</td>\n",
       "      <td>0.477035</td>\n",
       "      <td>0.454939</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.643144  0.272574  0.615783  0.501591  0.289880  0.181768  0.203608   \n",
       "1    0.601496  0.390260  0.595743  0.449417  0.514309  0.431017  0.462512   \n",
       "2    0.210090  0.360839  0.233501  0.102906  0.811321  0.811361  0.565604   \n",
       "3    0.629893  0.156578  0.630986  0.489290  0.430351  0.347893  0.463918   \n",
       "4    0.258839  0.202570  0.267984  0.141506  0.678613  0.461996  0.369728   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "563  0.690000  0.428813  0.678668  0.566490  0.526948  0.296055  0.571462   \n",
       "564  0.622320  0.626987  0.604036  0.474019  0.407782  0.257714  0.337395   \n",
       "565  0.455251  0.621238  0.445788  0.303118  0.288165  0.254340  0.216753   \n",
       "566  0.644564  0.663510  0.665538  0.475716  0.588336  0.790197  0.823336   \n",
       "567  0.036869  0.501522  0.028540  0.015907  0.000000  0.074351  0.000000   \n",
       "\n",
       "            7         8         9  ...        21        22        23  \\\n",
       "0    0.348757  0.379798  0.141323  ...  0.303571  0.539818  0.435214   \n",
       "1    0.635686  0.509596  0.211247  ...  0.360075  0.508442  0.374508   \n",
       "2    0.522863  0.776263  1.000000  ...  0.385928  0.241347  0.094008   \n",
       "3    0.518390  0.378283  0.186816  ...  0.123934  0.506948  0.341575   \n",
       "4    0.402038  0.518687  0.551179  ...  0.312633  0.263908  0.136748   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "563  0.690358  0.336364  0.132056  ...  0.383262  0.576174  0.452664   \n",
       "564  0.486630  0.349495  0.113100  ...  0.699094  0.520892  0.379915   \n",
       "565  0.263519  0.267677  0.137321  ...  0.589019  0.379949  0.230731   \n",
       "566  0.755467  0.675253  0.425442  ...  0.730277  0.668310  0.402035   \n",
       "567  0.000000  0.266162  0.187026  ...  0.489072  0.043578  0.020497   \n",
       "\n",
       "           24        25        26        27        28        29  class  \n",
       "0    0.347553  0.154563  0.192971  0.639175  0.233590  0.222878    1.0  \n",
       "1    0.483590  0.385375  0.359744  0.835052  0.403706  0.213433    1.0  \n",
       "2    0.915472  0.814012  0.548642  0.884880  1.000000  0.773711    1.0  \n",
       "3    0.437364  0.172415  0.319489  0.558419  0.157500  0.142595    1.0  \n",
       "4    0.712739  0.482784  0.427716  0.598282  0.477035  0.454939    1.0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "563  0.461137  0.178527  0.328035  0.761512  0.097575  0.105667    1.0  \n",
       "564  0.300007  0.159997  0.256789  0.559450  0.198502  0.074315    1.0  \n",
       "565  0.282177  0.273705  0.271805  0.487285  0.128721  0.151909    1.0  \n",
       "566  0.619626  0.815758  0.749760  0.910653  0.497142  0.452315    1.0  \n",
       "567  0.124084  0.036043  0.000000  0.000000  0.257441  0.100682   -1.0  \n",
       "\n",
       "[568 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read CSV\n",
    "df=pd.read_csv(dataset_path)\n",
    "\n",
    "diagnosis_col = df.iloc[:,-1]\n",
    "df = df.iloc[: , :-1]\n",
    "df['class'] = diagnosis_col\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLzynCxOpHBX"
   },
   "source": [
    "---\n",
    "<a id=\"section33\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.3. Generate images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate the images with the `generateImages()` generic function. Likewise, we create a dataset that will have the path of each of the samples with the corresponding image created for it. \n",
    "\n",
    "Note that each image is created based on a row, therefore, each numerical sample of the dataset will correspond to a particular image. In other words, we will have the same number of images as samples/rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manwest/Library/Python/3.9/lib/python/site-packages/TINTOlib/utils/Toolbox.py:148: RuntimeWarning: invalid value encountered in cast\n",
      "  result_table = result_table.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/supervised.csv\n"
     ]
    }
   ],
   "source": [
    "#Generate the images\n",
    "image_model.generateImages(df, images_folder)\n",
    "img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "print(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klS9PZsUjpDV"
   },
   "source": [
    "<a id=\"section34\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.4. Read images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COh9Th5jsDei"
   },
   "source": [
    "Once the images have been created we can read them. In this particular case, by using a pure CNN, we will use the images only to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/1.0/000000.png\n",
      "class\n",
      "-1.0    357\n",
      "1.0     211\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(img_paths)\n",
    "df[\"class\"] = df[\"class\"].astype(str)\n",
    "df[\"images\"]= images_folder + \"/\" + df[\"images\"]\n",
    "\n",
    "print(df[\"images\"][0])\n",
    "print(df[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 4. Pre-modelling phase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is ready, we load it into memory with an iterator in order to pass it to the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nb4Dd37rjpDm"
   },
   "source": [
    "---\n",
    "<a id=\"section41\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 4.1. Data curation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TjBcUbxjpDt"
   },
   "source": [
    "Split in train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BDyHty4-pjF5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_x = df.drop('class', axis = 1)\n",
    "df_y = df['class']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size = 0.40, random_state=42,stratify=df_y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.50, random_state=42,stratify=y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56      1.0\n",
       "523    -1.0\n",
       "449    -1.0\n",
       "472    -1.0\n",
       "420    -1.0\n",
       "       ... \n",
       "191    -1.0\n",
       "36     -1.0\n",
       "414    -1.0\n",
       "457    -1.0\n",
       "475    -1.0\n",
       "Name: class, Length: 340, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9Ix84V0ApjF8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis = 1)\n",
    "df_test = pd.concat([X_test, y_test], axis = 1)\n",
    "df_val = pd.concat([X_val, y_val], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnX_etdYpjF9",
    "outputId": "9104166d-9c5c-4ed3-b71b-c9aa23461559",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_train['class'].value_counts())\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(df_test['class'].value_counts())\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(df_val['class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a347tUZnjpED"
   },
   "source": [
    "---\n",
    "<a id=\"section42\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 4.2. Resize images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvXLjHzAjpEE"
   },
   "source": [
    "In our case, as we are going to train with a pre-trained network, we must resize it to the dimensions established by the network. Therefore, if you make a customised CNN, this cell is optional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0Jbdn_ypjF-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "teste_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebOBC5iypjGA",
    "outputId": "e1bf4be0-f486-460e-9bf6-90a7f87b1939",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjFY9rn2jpEL"
   },
   "source": [
    "---\n",
    "<a id=\"section43\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 4.3. Iterators</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each method generates images of **different pixel size**. For example:\n",
    "- `TINTO` method has a parameter that you can specify the size in pixels which by default is 20. \n",
    "- Other parameters such as `Combined` generates the size automatically and you must obtain them from the _shape_ of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = 369"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFYTHIPljpEM"
   },
   "source": [
    "Create iterators for train/test/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inaR7-KxpjGC",
    "outputId": "21305649-6133-43b8-c3cf-b6fa3faa5573",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_iter = train_datagen.flow_from_dataframe(\n",
    "    df_train, \n",
    "    target_size = (pixels, pixels),\n",
    "    x_col = 'images',\n",
    "    y_col = 'class',\n",
    "    class_mode = 'categorical',\n",
    "    #class_mode = 'binary',\n",
    "    #color_mode='grayscale',\n",
    "    color_mode='rgb',\n",
    "    batch_size = 8,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGPDhsFQpjGE",
    "outputId": "e473d2ba-806a-4a48-c530-2d91305bd9ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_iter = train_datagen.flow_from_dataframe(\n",
    "    df_val, \n",
    "    target_size = (pixels, pixels),\n",
    "    x_col = 'images',\n",
    "    y_col = 'class',\n",
    "    class_mode = 'categorical',\n",
    "    #class_mode = 'binary',\n",
    "    #color_mode='grayscale',\n",
    "    color_mode='rgb',\n",
    "    batch_size = 8,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkWY-9y3pjGF",
    "outputId": "2942429a-0a1f-4a68-91c2-ebd8dc797b8e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_iter = train_datagen.flow_from_dataframe(\n",
    "    df_test, \n",
    "    target_size = (pixels, pixels),\n",
    "    x_col = 'images',\n",
    "    y_col = 'class',\n",
    "    class_mode = 'categorical',\n",
    "    #class_mode = 'binary',\n",
    "    #color_mode='grayscale',\n",
    "    color_mode='rgb',\n",
    "    batch_size = 8,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YzRGsb9pjGG",
    "outputId": "1edff292-1127-40d6-b68f-1e6a4d92be32",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_iter.image_shape)\n",
    "print(valid_iter.image_shape)\n",
    "print(test_iter.image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xagy7N7ijpEX"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE0VunQYjpEY"
   },
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 5. Modelling with CNN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDfs9l-hjpEZ"
   },
   "source": [
    "Now we can start the CNN training. Before that we prepare the algorithm for reading data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn2U90FwjpEe"
   },
   "source": [
    "<a id=\"section51\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.1. CNN</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of a simple CNN. Note that we are not looking for the optimization of the CNN but to show an example of TINTOlib execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZl0AETUw1r8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import  BatchNormalization, Activation, Input, Concatenate\n",
    "from keras.utils import plot_model, np_utils\n",
    "\n",
    "dropout = 0.5\n",
    "epochs = 50\n",
    "n_class = df['class'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada\n",
    "input_shape = Input(shape=(pixels, pixels,3))\n",
    "        \n",
    "#Inicio de rama 1\n",
    "tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(input_shape)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "#tower_1 = Dropou(0.5)(tower_1)\n",
    "        \n",
    "tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "#tower_1 = Dropou(0.5)(tower_1)\n",
    "        \n",
    "tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "#tower_1 = Dropou(0.5)(tower_1)\n",
    "        \n",
    "tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "#tower_1 = Dropou(0.5)(tower_1)\n",
    "#Fin de rama 1\n",
    "        \n",
    "#Inicio de rama 2\n",
    "tower_2 = Conv2D(16, (5,5), activation='relu',padding=\"same\")(input_shape)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "#tower_2 = Dropou(0.5)(tower_2)\n",
    "        \n",
    "tower_2 = Conv2D(32, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "#tower_2 = Dropou(0.5)(tower_2)\n",
    "        \n",
    "tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "#tower_2 = Dropou(0.5)(tower_2)\n",
    "        \n",
    "tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "#tower_2 = Dropou(0.5)(tower_2)\n",
    "#Fin de rama 2\n",
    "            \n",
    "#Concatenación de las 2 ramas\n",
    "merged = Concatenate(axis=1)([tower_1, tower_2])\n",
    "        \n",
    "#Aplanamiento\n",
    "merged = Flatten()(merged)\n",
    "        \n",
    "#Capas adicionales\n",
    "out = Dense(256, activation='relu')(merged)\n",
    "out = Dense(128, activation='sigmoid')(out)\n",
    "out = Dense(64, activation='sigmoid')(out)\n",
    "out = Dense(32, activation='sigmoid')(out)\n",
    "        \n",
    "#Capa final de clasificación\n",
    "out = Dense(n_class, activation='softmax')(out)\n",
    "        \n",
    "model = Model(input_shape, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "model.summary()\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DC3Ft7sppjGI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name = 'tp'),\n",
    "      tf.keras.metrics.FalsePositives(name = 'fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name = 'tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name = 'fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name ='accuracy'),\n",
    "      tf.keras.metrics.Precision(name = 'precision'),\n",
    "      tf.keras.metrics.Recall(name = 'recall'),\n",
    "      tf.keras.metrics.AUC(name = 'auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owmN8gR-jpEh"
   },
   "source": [
    "<a id=\"section52\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.2. Compile and fit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to **specify the loss** depending on whether you have a binary or multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFxZU2q6pjGJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#opt = Adam(learning_rate=1e-3)\n",
    "model.compile(\n",
    "                #optimizer = sgd,\n",
    "                optimizer = 'adam',\n",
    "                #optimizer = 'Adadelta',\n",
    "                #optimizer = 'Adamax',\n",
    "                #optimizer = opt,\n",
    "                metrics = METRICS,\n",
    "                #metrics = ['accuracy'],\n",
    "                \n",
    "                #loss = 'binary_crossentropy'\n",
    "                loss = 'categorical_crossentropy'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelfitprogress = model.fit(\n",
    "                              train_iter,\n",
    "                              validation_data = valid_iter,\n",
    "                              epochs = epochs,\n",
    "                              steps_per_epoch = df_train.shape[0]//train_iter.batch_size,\n",
    "                              validation_steps = df_val.shape[0]//valid_iter.batch_size\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R2jytfijpEp"
   },
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 6. Results</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-1vHY9rjpEq"
   },
   "source": [
    "Finally, we can evaluate our CNN with the images created by TINTOlib in any of the ways represented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R2jytfijpEp"
   },
   "source": [
    "---\n",
    "<a id=\"section61\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.1. Train/Validation representation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "-Ls6_Vu7pjGL",
    "outputId": "35f21788-cd17-4377-9d88-79118f992164",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(modelfitprogress.history['loss'], color = 'red', label = 'loss')\n",
    "plt.plot(modelfitprogress.history['val_loss'], color = 'green', label = 'val loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "#plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "TWtsezuVpjGM",
    "outputId": "a06dccf3-da2d-4060-f67f-2046b547707b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(modelfitprogress.history['accuracy'], color = 'red', label = 'accuracy')\n",
    "plt.plot(modelfitprogress.history['val_accuracy'], color = 'green', label = 'val accuracy')\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R2jytfijpEp"
   },
   "source": [
    "---\n",
    "<a id=\"section62\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.2. Validation/Test evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-14T19:27:24.254144Z",
     "iopub.status.busy": "2022-11-14T19:27:24.253678Z",
     "iopub.status.idle": "2022-11-14T19:28:06.367196Z",
     "shell.execute_reply": "2022-11-14T19:28:06.366140Z",
     "shell.execute_reply.started": "2022-11-14T19:27:24.254102Z"
    },
    "id": "MtDLUW_QpjGO",
    "outputId": "1e8c02c1-0256-49cf-bd58-12e60bea38c6"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(valid_iter, steps = df_val.shape[0]//valid_iter.batch_size)\n",
    "print(\"Loss in validation: {} \\nAccuracy in validation: {}\".format(score[0], score[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-14T19:28:06.369726Z",
     "iopub.status.busy": "2022-11-14T19:28:06.369356Z",
     "iopub.status.idle": "2022-11-14T19:28:47.388501Z",
     "shell.execute_reply": "2022-11-14T19:28:47.387465Z",
     "shell.execute_reply.started": "2022-11-14T19:28:06.369687Z"
    },
    "id": "27tFyGE8pjGO",
    "outputId": "51f9d766-3e48-4f24-ea4f-a4e48e380444"
   },
   "outputs": [],
   "source": [
    "score_test = model.evaluate(test_iter, steps = df_test.shape[0]//test_iter.batch_size)\n",
    "print(\"Loss in test: {} \\nAccuracy in test: {}\".format(score_test[0], score_test[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_test[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_images = next(test_iter)[0]\n",
    "prediction = model.predict(test_iter, steps = np.math.ceil(test_iter.samples/test_iter.batch_size))\n",
    "#prediction = model.predict(test_images)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R2jytfijpEp"
   },
   "source": [
    "<a id=\"section62\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.3. Sklearn metrics evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score,precision_score, recall_score\n",
    "\n",
    "test_accuracy = score_test[5]\n",
    "test_auc = score_test[8]\n",
    "test_precision = score_test[6]\n",
    "test_recall = score_test[7]\n",
    "\n",
    "print(\"Test accuracy:\",test_accuracy)\n",
    "print(\"Test AUC:\",test_auc)\n",
    "print(\"Test precision:\",test_precision)\n",
    "print(\"Test recall:\",test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = modelfitprogress.history[\"accuracy\"][-1]\n",
    "train_auc = modelfitprogress.history[\"auc\"][-1]\n",
    "train_precision = modelfitprogress.history[\"precision\"][-1]\n",
    "train_recall = modelfitprogress.history[\"recall\"][-1]\n",
    "train_loss = modelfitprogress.history[\"loss\"][-1]\n",
    "\n",
    "print(\"Train accuracy:\",train_accuracy)\n",
    "print(\"Train AUC:\",train_auc)\n",
    "print(\"Train precision:\",train_precision)\n",
    "print(\"Train recall:\",train_recall)\n",
    "print(\"Train loss:\",train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracy = modelfitprogress.history[\"val_accuracy\"][-1]\n",
    "validation_auc = modelfitprogress.history[\"val_auc\"][-1]\n",
    "validation_precision = modelfitprogress.history[\"val_precision\"][-1]\n",
    "validation_recall = modelfitprogress.history[\"val_recall\"][-1]\n",
    "validation_loss = modelfitprogress.history[\"val_loss\"][-1]\n",
    "\n",
    "print(\"Validation accuracy:\",validation_accuracy)\n",
    "print(\"Validation AUC:\",validation_auc)\n",
    "print(\"Validation precision:\",validation_precision)\n",
    "print(\"Validation recall:\",validation_recall)\n",
    "print(\"Validation loss:\",validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ciBS76mpjGU"
   },
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
